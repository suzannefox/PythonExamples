# -*- coding: utf-8 -*-
"""
Created on Tue Nov  4 10:58:50 2014

@author: Suzanne
"""

import numpy as np
import pandas as pd
import matplotlib as plt
import os
import socket

# ===========================================================
# 1. Create some useful functions
# ===========================================================

# If any step goes badly wrong then use this global variable to halt the execution
# OK, so I know this is overkill for this coursework exercise, but if I build up this approach
# to working with file generally then it will save me time in the future, and I can reuse
# this code as it is generic
globalStop = False
def stop_here():
    globalStop=True

# ----------------------------------------------------------------
# Check file is utf-8 encoded, and write a new file if not    
# Based somewhat on code from http://stackoverflow.com/questions/436220/python-is-there-a-way-to-determine-the-encoding-of-text-file
import codecs
def file_encoding(data_path):
    for root, dirs, files in os.walk(data_path):
        for file in files:
            if file.endswith(".csv"):
                 print("===============================================")
                 print(os.path.join(root, file))              
                 check_encoding(data_path, file, stop_here)
                     
    if globalStop == True:
        print("")
        print("Fix the file encoding problem before proceeding")
        return
                 
def check_encoding(data_path, in_file, stop_here):

    got_encoding = False
    encodings = ['utf-8', 'windows-1250', 'windows-1252']

    for e in encodings:
        try:
            fh = codecs.open(data_path + in_file, 'r', encoding=e)
            fh.readlines()
            fh.seek(0)
        except UnicodeDecodeError:
            continue
            #print('got unicode error with %s , trying different encoding' % e)
        else:
            print('opening the file with encoding: {0}'.format(e))
            got_encoding = True

        # If the file is utf-8 then that's great        
        if e == 'utf-8':
            stop_here()
            return
           
        # If I don't know what encoding it is, that's a problem
        if got_encoding == False:
            print("FATAL ERROR : Need to determine encoding for {0}".format(data_path + in_file))
            stop_here()
            return

        # I know the encoding, but it's not utf-8 so need a utf-8 version
        print("WARNING : rewriting {0} with encoding {1} as utf-8 file".format(data_path + in_file, e))
        print("Rename the files manually before proceeding")
        stop_here()
        
        stream_in_file = codecs.open(data_path + in_file, 'r', e)
        stream_out_file = codecs.open(data_path + 'NEW_' + in_file, "w", "utf-8")
        
        for line in stream_in_file:
            stream_out_file.write(line)


# Investigate the csv files by reading them into a dataframe and then analysing the dataframe
# for Nans, means and a few other things
def data_investigate(data_path):
    
    # Make a list of all the CSV files, check they are encoded properly
    # pass a boolean to the function that checks the encoding, so if we have a file
    # that we don't know about the processing doesn't go any further than here
      
    # Have a look at the header of each file. Print to a file so I 
    # can see what's going on more easily
    diag_file = open(data_path + "datadiagnostics.txt", 'w')
    
    for root, dirs, files in os.walk(data_path):
        for file in files:
            if file.endswith(".csv"):
                 print("===============================================")
                 print("===============================================", file=diag_file)
                 
                 in_file = pd.read_csv(data_path + file, skiprows=19)
                 print('File is {0}, Rows = {1}, Cols = {2}'.format(file, in_file.shape[0], in_file.shape[1]))
                 print('File is {0}, Rows = {1}, Cols = {2}'.format(file, in_file.shape[0], in_file.shape[1]), file=diag_file)

                 print(df_analysis(in_file))
                 print(df_analysis(in_file),file=diag_file)
                 
    diag_file.close()

# Generic function to analyse a dataframe and return some useful summary information
# NB This is all my own work, I've been developing this as the course has gone along, and adding 
#    to it as I see the sorts of stats I'll be interested in, saves me having to write the 
#    same sort of stuff for each project
def df_analysis(inDataFrame):
    icol=0
    meandatatypes=['float64','int64','float']
    df_dtypes = inDataFrame.dtypes

    df = pd.DataFrame(columns=['offset','colname','coltype',"IsNumeric",'Nan_Count','Valid_Count','Nan %','Total', \
                               'Min','Max','Mean','Std dev','Var'])

    for col in inDataFrame:
        df.loc[icol]=[icol, \
                      col, \
                      df_dtypes[col], \
                      False,
                      inDataFrame[col].isnull().sum(), \
                      inDataFrame[col].count(), \
                      0, \
                      0, \
                      0, \
                      0, \
                      0, \
                      0, \
                      0]
                      
        if df_dtypes[col] in meandatatypes: 
            df.ix[icol,"IsNumeric"]=True
            df.ix[icol,'Min']=inDataFrame[col].min()
            df.ix[icol,'Max']=inDataFrame[col].max()
            df.ix[icol,'Mean']=inDataFrame[col].mean()
            df.ix[icol,'Std dev']=inDataFrame[col].std()
            df.ix[icol,'Var']=inDataFrame[col].var()
        #elif df_dtypes[col] in ['object']:
            #df.ix[icol,'Min']=inDataFrame[col].min()[0:3]
            #df.ix[icol,'Max']=inDataFrame[col].max()[0:3]

        icol+=1
        
    df['Total']=df['Nan_Count']+df['Valid_Count']
    df['Nan %']=(df['Nan_Count']/df['Total']) * 100
    return df

# ======================================================================================
# The main thing. 
# I don't want to run everything every time, so startstep is an integer arguement which
# allows me to choose which step I start at just by 1 keypress rather than having to comment
# out whole sections of code as I develop my program (I kept getting confused doing it that way)
# ======================================================================================
def main(startstep):
    # Find out whether I am running this at home or at City Uni nd set direcories accordingly
    MyComputer=socket.gethostname()
    if MyComputer[0:4]=='Suza':
        data_path = 'C:/Users/Public/Documents/MSc-DataScience/INM430/CW01/Data/'

    # Step 1. Check the file encodings
    if 1 >= startstep:
        file_encoding(data_path)
        if globalStop == True:
            return
    
    # Step 2. Have a look at all the data files, checks for Nans and general clenliness
    if 2 >= startstep:
        data_investigate(data_path)
        
    # Step 3. Having chosen the files I want to use, 
    if 3 >= startstep:
        print("Step 3")

    if 4 >= startstep:
        print("Step 4")
    
# ========================================================================================
# Finally, run the program, choosing which step to start at.
# ========================================================================================
if __name__ == "__main__":
    main(4)
